{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Concatenates all fasta files in a folder into a single fasta file.\n",
    "There's special code to compensate for alphabetical sorting between 1, 2, ... 10, ... 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "from sys import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\josiah\\Projects\\DDV\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Genomes\\Human\\Human All Alternates hg38\nD:\\Genomes\\Chimpanzee panTro\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir(\"D:\\Genomes\\Chimpanzee panTro\")\n",
    "# os.chdir(\"D:\\Genomes\\Chimpanzee panTro\\panTro3 May 2016\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fasta-splitter-0.2.4', 'panTro3 May 2016', 'panTro4.fa']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob('*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human sorting logic for single digit numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['elm0', 'elm1', 'Elm2', 'elm9', 'elm10', 'Elm11', 'Elm12', 'elm13']\n"
     ]
    }
   ],
   "source": [
    "from natsort import natsorted, ns\n",
    "x = ['Elm11', 'Elm12', 'Elm2', 'elm0', 'elm1', 'elm10', 'elm13', 'elm9']\n",
    "print(natsorted(x, alg=ns.IGNORECASE))  # or alg=ns.IC\n",
    "# ['elm0', 'elm1', 'Elm2', 'elm9', 'elm10', 'Elm11', 'Elm12', 'elm13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chr1.fa', 'chr2.fa', 'chr3.fa', 'chr4.fa', 'chr5.fa', 'chr6.fa', 'chr7.fa', 'chr8.fa', 'chr9.fa', 'chr10.fa', 'chr11.fa', 'chr12.fa', 'chr13.fa', 'chr14.fa', 'chr15.fa', 'chr16.fa', 'chr17.fa', 'chr18.fa', 'chr19.fa', 'chr20.fa', 'chr21.fa', 'chr22.fa', 'chrX.fa', 'chrY.fa', 'chrM.fa']\n"
     ]
    }
   ],
   "source": [
    "core_chromosomes = natsorted([f for f in glob('*') if '_' not in f], alg=ns.IGNORECASE)\n",
    "core_chromosomes = ['chr1.fa', 'chr2.fa', 'chr3.fa', 'chr4.fa', 'chr5.fa', 'chr6.fa', 'chr7.fa', 'chr8.fa', 'chr9.fa', 'chr10.fa', 'chr11.fa', 'chr12.fa', 'chr13.fa', 'chr14.fa', 'chr15.fa', 'chr16.fa', 'chr17.fa', 'chr18.fa', 'chr19.fa', 'chr20.fa', 'chr21.fa', 'chr22.fa', 'chrX.fa', 'chrY.fa', 'chrM.fa']\n",
    "print(core_chromosomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chr1_GL383518v1_alt.fa', 'chr1_GL383519v1_alt.fa', 'chr1_GL383520v2_alt.fa', 'chr1_KI270706v1_random.fa', 'chr1_KI270707v1_random.fa', 'chr1_KI270708v1_random.fa', 'chr1_KI270709v1_random.fa', 'chr1_KI270710v1_random.fa', 'chr1_KI270711v1_random.fa', 'chr1_KI270712v1_random.fa', 'chr1_KI270713v1_random.fa', 'chr1_KI270714v1_random.fa', 'chr1_KI270759v1_alt.fa', 'chr1_KI270760v1_alt.fa', 'chr1_KI270761v1_alt.fa', 'chr1_KI270762v1_alt.fa', 'chr1_KI270763v1_alt.fa', 'chr1_KI270764v1_alt.fa', 'chr1_KI270765v1_alt.fa', 'chr1_KI270766v1_alt.fa', 'chr1_KI270892v1_alt.fa', 'chr2_GL383521v1_alt.fa', 'chr2_GL383522v1_alt.fa', 'chr2_GL582966v2_alt.fa', 'chr2_KI270715v1_random.fa', 'chr2_KI270716v1_random.fa', 'chr2_KI270767v1_alt.fa', 'chr2_KI270768v1_alt.fa', 'chr2_KI270769v1_alt.fa', 'chr2_KI270770v1_alt.fa', 'chr2_KI270771v1_alt.fa', 'chr2_KI270772v1_alt.fa', 'chr2_KI270773v1_alt.fa', 'chr2_KI270774v1_alt.fa', 'chr2_KI270775v1_alt.fa', 'chr2_KI270776v1_alt.fa', 'chr2_KI270893v1_alt.fa', 'chr2_KI270894v1_alt.fa', 'chr3_GL000221v1_random.fa', 'chr3_GL383526v1_alt.fa', 'chr3_JH636055v2_alt.fa', 'chr3_KI270777v1_alt.fa', 'chr3_KI270778v1_alt.fa', 'chr3_KI270779v1_alt.fa', 'chr3_KI270780v1_alt.fa', 'chr3_KI270781v1_alt.fa', 'chr3_KI270782v1_alt.fa', 'chr3_KI270783v1_alt.fa', 'chr3_KI270784v1_alt.fa', 'chr3_KI270895v1_alt.fa', 'chr3_KI270924v1_alt.fa', 'chr3_KI270934v1_alt.fa', 'chr3_KI270935v1_alt.fa', 'chr3_KI270936v1_alt.fa', 'chr3_KI270937v1_alt.fa', 'chr4_GL000008v2_random.fa', 'chr4_GL000257v2_alt.fa', 'chr4_GL383527v1_alt.fa', 'chr4_GL383528v1_alt.fa', 'chr4_KI270785v1_alt.fa', 'chr4_KI270786v1_alt.fa', 'chr4_KI270787v1_alt.fa', 'chr4_KI270788v1_alt.fa', 'chr4_KI270789v1_alt.fa', 'chr4_KI270790v1_alt.fa', 'chr4_KI270896v1_alt.fa', 'chr4_KI270925v1_alt.fa', 'chr5_GL000208v1_random.fa', 'chr5_GL339449v2_alt.fa', 'chr5_GL383530v1_alt.fa', 'chr5_GL383531v1_alt.fa', 'chr5_GL383532v1_alt.fa', 'chr5_GL949742v1_alt.fa', 'chr5_KI270791v1_alt.fa', 'chr5_KI270792v1_alt.fa', 'chr5_KI270793v1_alt.fa', 'chr5_KI270794v1_alt.fa', 'chr5_KI270795v1_alt.fa', 'chr5_KI270796v1_alt.fa', 'chr5_KI270897v1_alt.fa', 'chr5_KI270898v1_alt.fa', 'chr6_GL000250v2_alt.fa', 'chr6_GL000251v2_alt.fa', 'chr6_GL000252v2_alt.fa', 'chr6_GL000253v2_alt.fa', 'chr6_GL000254v2_alt.fa', 'chr6_GL000255v2_alt.fa', 'chr6_GL000256v2_alt.fa', 'chr6_GL383533v1_alt.fa', 'chr6_KB021644v2_alt.fa', 'chr6_KI270758v1_alt.fa', 'chr6_KI270797v1_alt.fa', 'chr6_KI270798v1_alt.fa', 'chr6_KI270799v1_alt.fa', 'chr6_KI270800v1_alt.fa', 'chr6_KI270801v1_alt.fa', 'chr6_KI270802v1_alt.fa', 'chr7_GL383534v2_alt.fa', 'chr7_KI270803v1_alt.fa', 'chr7_KI270804v1_alt.fa']\n"
     ]
    }
   ],
   "source": [
    "extra_contigs = natsorted([f for f in glob('*') if '_' in f], alg=ns.IGNORECASE)\n",
    "print(extra_contigs[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_files(filenames, aggregate_name, insert_headers=False):\n",
    "    with open(aggregate_name, 'w') as out:\n",
    "        for filename in filenames:\n",
    "            if insert_headers:\n",
    "                chr = os.path.splitext(os.path.basename(filename))[0]\n",
    "                out.write('>' + chr + '\\n')\n",
    "                print(chr)\n",
    "            else:\n",
    "                print('Opening', filename)\n",
    "            with open(filename, 'r') as infile:\n",
    "                for line in infile.readlines():\n",
    "                    out.writelines([line])\n",
    "    print('Done concatting files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_files(core_chromosomes + extra_contigs, 'Human v38 All Variants.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\josiah\\Projects\\DDV\nD:\\Genomes\\Gorilla\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir('D:\\Genomes\\Gorilla')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">ENA|CYUI01004130|CYUI01004130.1 Gorilla gorilla gorilla genome assembly, contig: 005229F_quiver \n"
     ]
    }
   ],
   "source": [
    "def print_contigs(contig_name, in_file):\n",
    "    output_this = False\n",
    "    line_after = False\n",
    "    with open(in_file, 'r') as input:\n",
    "        with open(contig_name + '.fa', 'w') as out:\n",
    "            for line in input.readlines():\n",
    "                if line_after:\n",
    "                    print(line)\n",
    "                    line_after = False\n",
    "                if line and line[0] == '>':\n",
    "                    if output_this:\n",
    "                        break  # done with contig\n",
    "                    if contig_name in line and 'random' not in line:\n",
    "                        output_this = True\n",
    "                        print(line, end=\"\")\n",
    "                if output_this:\n",
    "                    out.writelines([line])\n",
    "print_contigs('CYUI01004130', in_file='CYUI01000001-CYUI01015997.fasta')  # Gorilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasta_samples():\n",
    "    \"\"\"Take a sample from these chromosomes for testing purposes\"\"\"\n",
    "    for filename in 'ref_GRCH38_chr9.fa ref_GRCH37_chr9.fa ref_GRCH35_chr9.fa'.split():\n",
    "        with open(filename + '__sample.fa', 'w') as out:\n",
    "            print('Opening', filename)\n",
    "            with open(filename, 'r') as infile:\n",
    "                infile.readline()  # skip the title\n",
    "                content = ''.join(infile.read().splitlines())\n",
    "                start = 37650000  # 37,600,000\n",
    "                content = content[start : start + 10000000 // 3]\n",
    "                # N_start = 39665004\n",
    "                # if filename == 'ref_GRCH38_chr9.fa':\n",
    "                #     print('Inserting GAP')\n",
    "                #     content = content[: N_start-start] + 'X' * (39714488-N_start) + content[N_start-start:]\n",
    "                # N_start += 230000\n",
    "                # if filename == 'ref_GRCH37_chr9.fa':\n",
    "                #     print('Inserting GAP')\n",
    "                #     content = content[: N_start-start] + 'X' * 50484 + content[N_start-start:]\n",
    "                out.write(content)\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening panTro4ToHg38.over.chain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n"
     ]
    }
   ],
   "source": [
    "def sample_chain_file():\n",
    "    filename = 'panTro4ToHg38.over.chain'\n",
    "    line_count = 0\n",
    "    # with open(filename + '__chr20_sample.chain', 'w') as out:\n",
    "    print('Opening', filename)\n",
    "    with open(filename, 'r') as infile:\n",
    "        printing = False\n",
    "        for line in infile.readlines():\n",
    "            if line.startswith('chain'):\n",
    "                chain, score, tName, tSize, tStrand, tStart, \\\n",
    "                tEnd, qName, qSize, qStrand, qStart, qEnd, chain_id = line.split()\n",
    "                # if printing:\n",
    "                #     break  # only output the first chain\n",
    "                printing = 'chr20' in tName and 'chr20' not in qName  \n",
    "                if printing:\n",
    "                    line_count += 1\n",
    "                    # print(line)\n",
    "                    # out.write(line)  # write header\n",
    "            # else:\n",
    "            #     pieces = line.split()\n",
    "            #     if printing:\n",
    "            #         out.write(line)\n",
    "                # if len(pieces) == 3:\n",
    "                #     size, gap_reference, gap_query = pieces\n",
    "                #     if printing:\n",
    "                #         out.write(line)\n",
    "                #         # print(size, gap_reference, gap_query)\n",
    "                # elif len(pieces) == 1:\n",
    "                #     if printing:\n",
    "                #         out.writelines(pieces)\n",
    "    print(line_count)\n",
    "                    \n",
    "sample_chain_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138394717 138252981 vs 141213431 141143431\n141736\n70000\n113144517\n"
     ]
    }
   ],
   "source": [
    "filename = 'hg38ToHg19.over.chain' + '__sample.chain'\n",
    "ref_count = 0\n",
    "query_count = 0\n",
    "total_size = 0\n",
    "with open(filename, 'r') as chainfile:\n",
    "    for line in chainfile.readlines():\n",
    "        if line.startswith('chain'):\n",
    "            chain, score, tName, tSize, tStrand, tStart, \\\n",
    "            tEnd, qName, qSize, qStrand, qStart, qEnd, chain_id = line.split()\n",
    "        else:\n",
    "            pieces = line.split()\n",
    "            if len(pieces) == 3:\n",
    "                size, gap_reference, gap_query = [int(x) for x in pieces]\n",
    "                ref_count += size + gap_reference\n",
    "                total_size += size\n",
    "                query_count += size + gap_query\n",
    "\n",
    "            elif len(pieces) == 1:\n",
    "                ref_count += int(pieces[0])\n",
    "                query_count += int(pieces[0])\n",
    "print(tSize, ref_count, \"vs\", qSize, query_count)\n",
    "print(int(tSize) - ref_count)\n",
    "print(int(qSize) - query_count)\n",
    "print(total_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\josiah\\Projects\\DDV\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening chr20_hg38_gapped.fa\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening chr20_panTro4_gapped.fa\n"
     ]
    }
   ],
   "source": [
    "def sample_file():\n",
    "    os.chdir(\"D:\\josiah\\Projects\\DDV\")\n",
    "    print(os.getcwd())\n",
    "    for filename in ['chr20_hg38_gapped.fa', 'chr20_panTro4_gapped.fa']:\n",
    "        with open(filename, 'r') as infile:\n",
    "            lines = infile.read().splitlines()\n",
    "        char_count = 0\n",
    "        with open(filename, 'w') as out:  # overwrite the file\n",
    "            print('Opening', filename)\n",
    "            for line in lines:\n",
    "                out.writelines([line + '\\n'])  \n",
    "                char_count += 70\n",
    "                if char_count >= 10 * 100 * 1000:\n",
    "                    break\n",
    "sample_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\josiah\\Projects\\DDV\nD:\\josiah\\Projects\\DDV\\bin\\Release\\output\\dnadata\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir(r\"D:\\josiah\\Projects\\DDV\\bin\\Release\\output\\dnadata\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hg38_unique_vs_panTro4_chr1\\\\chr1_hg38_unique.fa',\n 'Hg38_unique_vs_panTro4_chr2\\\\chr2_hg38_unique.fa',\n 'Hg38_unique_vs_panTro4_chr3\\\\chr3_hg38_unique.fa',\n 'Hg38_unique_vs_panTro4_chr4\\\\chr4_hg38_unique.fa',\n 'Hg38_unique_vs_panTro4_chr5\\\\chr5_hg38_unique.fa',\n 'Hg38_unique_vs_panTro4_chr6\\\\chr6_hg38_unique.fa',\n 'Hg38_unique_vs_panTro4_chr7\\\\chr7_hg38_unique.fa',\n 'Hg38_unique_vs_panTro4_chr8\\\\chr8_hg38_unique.fa',\n 'Hg38_unique_vs_panTro4_chr9\\\\chr9_hg38_unique.fa',\n 'Hg38_unique_vs_panTro4_chr10\\\\chr10_hg38_unique.fa',\n 'Hg38_unique_vs_panTro4_chr11\\\\chr11_hg38_unique.fa',\n 'Hg38_unique_vs_panTro4_chr12\\\\chr12_hg38_unique.fa',\n 'Hg38_unique_vs_panTro4_chr13\\\\chr13_hg38_unique.fa',\n 'Hg38_unique_vs_panTro4_chr14\\\\chr14_hg38_unique.fa',\n 'Hg38_unique_vs_panTro4_chr15\\\\chr15_hg38_unique.fa',\n 'Hg38_unique_vs_panTro4_chr16\\\\chr16_hg38_unique.fa',\n 'Hg38_unique_vs_panTro4_chr17\\\\chr17_hg38_unique.fa',\n 'Hg38_unique_vs_panTro4_chr18\\\\chr18_hg38_unique.fa',\n 'Hg38_unique_vs_panTro4_chr19\\\\chr19_hg38_unique.fa',\n 'Hg38_unique_vs_panTro4_chr20\\\\chr20_hg38_unique.fa',\n 'Hg38_unique_vs_panTro4_chr21 backup\\\\chr21_unique.fa',\n 'Hg38_unique_vs_panTro4_chr21\\\\chr21_hg38_unique.fa',\n 'Hg38_unique_vs_panTro4_chr22\\\\chr22_hg38_unique.fa',\n 'Hg38_unique_vs_panTro4_chrX\\\\chrX_hg38_unique.fa',\n 'Hg38_unique_vs_panTro4_chrY\\\\chrY_hg38_unique.fa']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "from natsort import natsorted, ns\n",
    "fasta_list = glob('Hg38_unique_vs_panTro4_chr*/*.fa')\n",
    "fasta_list = natsorted(fasta_list, alg=ns.IGNORECASE)\n",
    "fasta_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1_hg38_unique\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr2_hg38_unique\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr3_hg38_unique\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr4_hg38_unique\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr5_hg38_unique\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr6_hg38_unique\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr7_hg38_unique\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr8_hg38_unique\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr9_hg38_unique\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr10_hg38_unique\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr11_hg38_unique\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr12_hg38_unique\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr13_hg38_unique\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr14_hg38_unique\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr15_hg38_unique\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr16_hg38_unique\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr17_hg38_unique\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr18_hg38_unique\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr19_hg38_unique\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr20_hg38_unique\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr21_unique\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr21_hg38_unique\nchr22_hg38_unique\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrX_hg38_unique\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrY_hg38_unique\nDone concatting files\n"
     ]
    }
   ],
   "source": [
    "aggregate_files(fasta_list, 'Human38_Unique.fa', insert_headers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">chr1_hg38_unique\n\nTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAAC\n\nCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCAACCCTAACCCTAACCCTAACCCTAACCCTAA\n\n"
     ]
    }
   ],
   "source": [
    "with open('Human38_Unique.fa', 'r') as infile:  #'hg38_hgc.fa'\n",
    "    print(infile.readline())\n",
    "    print(infile.readline())\n",
    "    print(infile.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\josiah\\Projects\\DDV\\HongKong\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('HongKong')\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "def extract_contig(genome_file, contig_name, out_filename):\n",
    "    printing = False\n",
    "    with open(genome_file, 'r') as genome:\n",
    "        with open(out_filename, 'w') as out:\n",
    "            for line in genome:\n",
    "                if line.startswith('>'):\n",
    "                    printing = False\n",
    "                    if line.startswith('>' + contig_name):\n",
    "                        printing = True\n",
    "                    elif printing:\n",
    "                        break\n",
    "                if printing:\n",
    "                    out.write(line)\n",
    "\n",
    "extract_contig('susie3_agp.fasta', 'chr22', 'susie3_chr22.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">hgc1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">hgc2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">hgc3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">hgc4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">hgc5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">hgc6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">hgc7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">hgc8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">hgc9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">hgc10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">hgc11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">hgc12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">hgc13\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0d550394ebaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Done\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mprint_contig_headers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"HongKong\\hg38_hc.fa\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-0d550394ebaa>\u001b[0m in \u001b[0;36mprint_contig_headers\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprint_contig_headers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'>'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python34\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "def print_contig_headers(filename):\n",
    "    with open(filename, 'r') as infile:\n",
    "        for line in infile:\n",
    "            if line.startswith('>'):\n",
    "                print(line, end='')\n",
    "    print(\"Done\")\n",
    "print_contig_headers(r\"HongKong\\hg38_hc.fa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}